{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natsumeyuya/portfolio/blob/master/%E5%96%B6%E6%A5%AD%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E3%83%AA%E3%82%B9%E3%83%88%E6%94%B9%E8%A8%82%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16ktOggTRO43"
      },
      "outputs": [],
      "source": [
        "#インポート\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "#抽出したデータの格納先\n",
        "df = pd.DataFrame()\n",
        "#クラス\n",
        "class Restaurant_list:\n",
        "  def __init__(self,base_url,district):\n",
        "    self.district = district\n",
        "    self.base_url = base_url\n",
        "  #URL取得\n",
        "  def get_url(self):\n",
        "    num = 1\n",
        "    url_list = []\n",
        "    append = url_list.append\n",
        "    while num < 60:\n",
        "      url = self.base_url + str(num)\n",
        "      append(url)\n",
        "      html = requests.get(url)\n",
        "      soup = BeautifulSoup(html.content, 'lxml')\n",
        "      print(soup.find(class_ = 'c-page-count__num').text)\n",
        "      if soup.find(class_ = 'c-page-count__num').text == \"0\":\n",
        "        break\n",
        "      num += 1\n",
        "      time.sleep(1)\n",
        "    return url_list\n",
        "\n",
        "  #データの抽出\n",
        "  def get_data(self,url_list):\n",
        "    shop_list = []\n",
        "    genre_info = []\n",
        "    area_info = []\n",
        "    rate_list = []\n",
        "    call_list = []\n",
        "    rest_list = []\n",
        "    homepage_list = []\n",
        "    number = str(len(url_list))\n",
        "\n",
        "    for target_url in url_list[:len(url_list)-1]:\n",
        "      html = requests.get(target_url)\n",
        "      soup = BeautifulSoup(html.content, 'lxml')\n",
        "      print(\"残り\" + number + \"回\")\n",
        "      number = str(int(number) - 1)\n",
        "      #店舗名\n",
        "      raw_data = soup.find_all('a', class_='list-rst__rst-name-target cpy-rst-name')\n",
        "      shop_list += [name.text for name in raw_data]\n",
        "      shop_url_list = [shop_url.get('href') for shop_url in raw_data]\n",
        "\n",
        "      #ジャンル\n",
        "      genre_info += [genre.text.rstrip().split(\"/\")[1] for genre in soup.find_all('div', class_='list-rst__area-genre cpy-area-genre')]\n",
        "\n",
        "      #エリア\n",
        "      area_info += [genre.text.strip().split(\"/\")[0] for genre in soup.find_all('div', class_='list-rst__area-genre cpy-area-genre')]\n",
        "\n",
        "      #評価点&ホームページ＆電話番号&定休日\n",
        "      append1 = rate_list.append\n",
        "      append2 = rest_list.append\n",
        "      append3 = homepage_list.append\n",
        "      append4 = call_list.append\n",
        "      for shop_url in shop_url_list:\n",
        "        response = requests.get(shop_url)\n",
        "        all_data = BeautifulSoup(response.content, 'lxml')\n",
        "        shop_header = all_data.find(class_ = 'rstdtl-header')\n",
        "        shop_data = all_data.find(class_ = 'rstinfo-table')\n",
        "        try:\n",
        "          rate = shop_header.find(class_=\"rdheader-rating__score-val-dtl\")\n",
        "          append1(float(rate.text))\n",
        "        except:\n",
        "          append1('-')\n",
        "        try:\n",
        "          rest = shop_header.find(class_ ='rdheader-subinfo__closed-text')\n",
        "          append2(rest.text.strip())\n",
        "        except:\n",
        "          append2('-')\n",
        "        try:\n",
        "          homepage = shop_data.find('p', class_ = 'homepage').find('a',class_ = 'c-link-arrow')\n",
        "          append3(homepage.get('href'))\n",
        "        except:\n",
        "          append3('-')\n",
        "        try:\n",
        "          call = shop_data.find(class_ = \"rstinfo-table__tel-num\")\n",
        "          append4(call.text)\n",
        "        except:\n",
        "          append4('-')\n",
        "        time.sleep(1)\n",
        "    #データフレームに格納\n",
        "    df[\"name\"] = shop_list\n",
        "    df[\"genre\"] = genre_info\n",
        "    df[\"area\"] = area_info\n",
        "    df[\"rate\"] = rate_list\n",
        "    df[\"call\"] = call_list\n",
        "    df[\"rest\"] = rest_list\n",
        "    df[\"homepage\"] = homepage_list\n",
        "\n",
        "    #欲しいデータの抽出\n",
        "    data = df[df['homepage'].str.contains('http:')]\n",
        "    data = data.reset_index()\n",
        "    data = data.drop('index',axis=1)\n",
        "    return data\n",
        "\n",
        "  #Excelへのデータの書き込み\n",
        "  def write_xlsx(self,data):\n",
        "    with pd.ExcelWriter('/content/drive/MyDrive/営業/営業リスト.xlsx',mode='a') as writer:\n",
        "      data.to_excel(writer, sheet_name= f\"{self.district}\")\n",
        "\n",
        "  #プログラム実行\n",
        "  def work(self):\n",
        "    print(f'{self.district}')\n",
        "    url_list = self.get_url()\n",
        "    data =  self.get_data(url_list)\n",
        "    self.write_xlsx(data)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpYxRfjbM0UX"
      },
      "outputs": [],
      "source": [
        "oosu =  Restaurant_list(\"https://tabelog.com/aichi/A2301/A230105/R1737/rstLst/\",\"大須観音\")\n",
        "yabatyou_1 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R10228/rstLst/RC/\",\"矢場町_レストラン\")\n",
        "yabatyou_2 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R10228/rstLst/MC/\",\"矢場町_ラーメン\")\n",
        "yabatyou_3 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R10228/rstLst/cafe/\",\"矢場町_カフェ\")\n",
        "yabatyou_4 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R10228/rstLst/SC/\",\"矢場町_パン\")\n",
        "yabatyou_5 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R10228/rstLst/bar/\",\"矢場町_バー\")\n",
        "sakae_1 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R4222/rstLst/RC/\",\"栄＿レストラン\")\n",
        "sakae_2 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R4222/rstLst/MC/\",\"栄＿ラーメン\")\n",
        "sakae_3 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R4222/rstLst/cafe/\",\"栄＿カフェ\")\n",
        "sakae_4 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R4222/rstLst/SC/\",\"栄＿パン\")\n",
        "sakae_5 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230103/R4222/rstLst/bar/\",\"栄＿バー\")\n",
        "nagoya_1 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230101/R7155/rstLst/RC/\",\"名古屋＿レストラン\")\n",
        "nagoya_2 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230101/R7155/rstLst/MC/\",\"名古屋＿ラーメン\")\n",
        "nagoya_3 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230101/R7155/rstLst/cafe/\",\"名古屋＿カフェ\")\n",
        "nagoya_4 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230101/R7155/rstLst/SC/\",\"名古屋＿パン\")\n",
        "nagoya_5 = Restaurant_list(\"https://tabelog.com/aichi/A2301/A230101/R7155/rstLst/bar/\",\"名古屋＿バー\")\n",
        "kamimaezu =  Restaurant_list(\"https://tabelog.com/aichi/A2301/A230105/R2722/rstLst/\",\"上前津\")\n",
        "higasi = Restaurant_list(\"https://tabelog.com/aichi/C23102/rstLst/\",\"東区\")\n",
        "syouwa = Restaurant_list(\"https://tabelog.com/aichi/C23107/rstLst/\",\"昭和区\")\n",
        "tikusa = Restaurant_list(\"https://tabelog.com/aichi/C23101/rstLst/\",\"千種区\")\n",
        "tennpaku = Restaurant_list(\"https://tabelog.com/aichi/C23116/rstLst/\",\"天白区\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QgusqXZ8L51rDFpevr5pSziI6P1PiL_w",
      "authorship_tag": "ABX9TyNfVOIL2S/NtvQETufoWUfd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}